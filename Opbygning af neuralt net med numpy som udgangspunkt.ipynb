{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96163bb9",
   "metadata": {},
   "source": [
    "Opbygning af neuralt net med numpy som udgangspunkt \n",
    "\n",
    " \n",
    "\n",
    "Casen er et 2-dimensionelt indgangsmønster.. \n",
    "\n",
    " \n",
    "\n",
    "Illustrerer sigmoid, fejlberegning ,træning o.a. grundbegreber \n",
    "\n",
    " mkilde : https://realpython.com/python-ai-neural-network/\n",
    " \n",
    "\n",
    "for nuværende indeholder notebooken kun slut resultatet.. Der er meget at gøre her!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b7d7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, learning_rate):\n",
    "        self.weights = np.array([np.random.randn(), np.random.randn()])\n",
    "        self.bias = np.random.randn()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def _sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def _sigmoid_deriv(self, x):\n",
    "        return self._sigmoid(x) * (1 - self._sigmoid(x))\n",
    "\n",
    "    def predict(self, input_vector):\n",
    "        layer_1 = np.dot(input_vector, self.weights) + self.bias\n",
    "        layer_2 = self._sigmoid(layer_1)\n",
    "        prediction = layer_2\n",
    "        return prediction\n",
    "\n",
    "    def _compute_gradients(self, input_vector, target):\n",
    "        layer_1 = np.dot(input_vector, self.weights) + self.bias\n",
    "        layer_2 = self._sigmoid(layer_1)\n",
    "        prediction = layer_2\n",
    "\n",
    "        derror_dprediction = 2 * (prediction - target)\n",
    "        dprediction_dlayer1 = self._sigmoid_deriv(layer_1)\n",
    "        dlayer1_dbias = 1\n",
    "        dlayer1_dweights = (0 * self.weights) + (1 * input_vector)\n",
    "\n",
    "        derror_dbias = (\n",
    "            derror_dprediction * dprediction_dlayer1 * dlayer1_dbias\n",
    "        )\n",
    "        derror_dweights = (\n",
    "            derror_dprediction * dprediction_dlayer1 * dlayer1_dweights\n",
    "        )\n",
    "\n",
    "        return derror_dbias, derror_dweights\n",
    "\n",
    "    def _update_parameters(self, derror_dbias, derror_dweights):\n",
    "        self.bias = self.bias - (derror_dbias * self.learning_rate)\n",
    "        self.weights = self.weights - (\n",
    "            derror_dweights * self.learning_rate\n",
    "        )\n",
    "\n",
    "    def train(self, input_vectors, targets, iterations):\n",
    "        cumulative_errors = []\n",
    "        for current_iteration in range(iterations):\n",
    "            # Pick a data instance at random\n",
    "            random_data_index = np.random.randint(len(input_vectors))\n",
    "\n",
    "            input_vector = input_vectors[random_data_index]\n",
    "            target = targets[random_data_index]\n",
    "\n",
    "            # Compute the gradients and update the weights\n",
    "            derror_dbias, derror_dweights = self._compute_gradients(\n",
    "                input_vector, target\n",
    "            )\n",
    "\n",
    "            self._update_parameters(derror_dbias, derror_dweights)\n",
    "\n",
    "            # Measure the cumulative error for all the instances\n",
    "            if current_iteration % 100 == 0:\n",
    "                cumulative_error = 0\n",
    "                # Loop through all the instances to measure the error\n",
    "                for data_instance_index in range(len(input_vectors)):\n",
    "                    data_point = input_vectors[data_instance_index]\n",
    "                    target = targets[data_instance_index]\n",
    "\n",
    "                    prediction = self.predict(data_point)\n",
    "                    error = np.square(prediction - target)\n",
    "\n",
    "                    cumulative_error = cumulative_error + error\n",
    "                cumulative_errors.append(cumulative_error)\n",
    "\n",
    "        return cumulative_errors\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "input_vectors = np.array(\n",
    "    [\n",
    "        [3, 1.5],\n",
    "        [2, 1],\n",
    "        [4, 1.5],\n",
    "        [3, 4],\n",
    "        [3.5, 0.5],\n",
    "        [2, 0.5],\n",
    "        [5.5, 1],\n",
    "        [1, 1],\n",
    "    ]\n",
    ")\n",
    "\n",
    "targets = np.array([0, 1, 0, 1, 0, 1, 1, 0])\n",
    "\n",
    "learning_rate = 0.1\n",
    "\n",
    "neural_network = NeuralNetwork(learning_rate)\n",
    "\n",
    "training_error = neural_network.train(input_vectors, targets, 10000)\n",
    "\n",
    "print(\"plotting\")\n",
    "\n",
    "#plt.plot(training_error)\n",
    "#plt.xlabel(\"Iterations\")\n",
    "#plt.ylabel(\"Error for all training instances\")\n",
    "#plt.savefig(\"cumulative_error.png\")\n",
    "plt.scatter(input_vectors[:,0],input_vectors[:,1],(targets+1)*8)\n",
    "plt.show()\n",
    "print (input_vectors)\n",
    "#testing\n",
    "testdata= np.array([[0,0]])\n",
    "testdata = np.append(testdata,4*np.random.random(10))\n",
    "testdata.reshape(2,6)\n",
    "print (testdata)\n",
    "testdata.reshape(6,2)\n",
    "print (testdata)\n",
    "\n",
    "#plt.scatter(testdata[:,0],testdata[:,1])   #,(targets+1)*8)\n",
    "#plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
